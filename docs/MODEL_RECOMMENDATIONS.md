# AI Model Recommendations for Robot Maintenance

## Available Models (Updated 2025)

### üöÄ GPT-5 / GPT-5 Pro (Latest - Check Availability)
**Status**: ‚ö†Ô∏è May be available in Azure OpenAI (check your region)

**Note**: GPT-5 exists, but "GPT-5 Pro" may not be the official Azure deployment name. Check your Azure Portal for exact model names.

**Best For**: 
- ‚úÖ **Hackathon demos** (most impressive)
- ‚úÖ Complex technical diagnostics
- ‚úÖ FANUC robot error analysis
- ‚úÖ Production-critical maintenance

**Pros:**
- ‚úÖ **Best reasoning** - Expert-level intelligence
- ‚úÖ **Most accurate** technical recommendations
- ‚úÖ **Superior understanding** of FANUC error codes
- ‚úÖ **Better structured output** (5-section format)
- ‚úÖ **Multi-turn reasoning** for complex problems

**Cons:**
- ‚ùå **Most expensive** (~$0.05-0.10 per 1K tokens)
- ‚ùå **Slower** (designed for deeper reasoning)
- ‚ùå **May not be available** in all Azure regions yet
- ‚ùå **May timeout** on simple requests (use background mode)

**Cost Estimate**: ~$5-10 for 100 events analyzed

**Deployment Name**: `gpt-5-pro` or `gpt-5`

---

### üèÜ GPT-4 (Recommended for Most Cases)
**Status**: ‚úÖ Widely available

**Best For**:
- ‚úÖ **Hackathon demos** (excellent quality)
- ‚úÖ Production use
- ‚úÖ Complex diagnostics
- ‚úÖ Balanced quality/cost

**Pros:**
- ‚úÖ Excellent reasoning
- ‚úÖ Great technical analysis
- ‚úÖ Good understanding of FANUC codes
- ‚úÖ Reliable structured output
- ‚úÖ Widely available

**Cons:**
- ‚ùå More expensive than GPT-3.5
- ‚ùå Slower than GPT-3.5

**Cost Estimate**: ~$2-5 for 100 events

**Deployment Name**: `gpt-4`

---

### ‚ö° GPT-4 Turbo
**Status**: ‚úÖ Available

**Best For**:
- ‚úÖ Balance of quality and speed
- ‚úÖ Faster than GPT-4, better than GPT-3.5

**Pros:**
- ‚úÖ Faster than GPT-4
- ‚úÖ Better than GPT-3.5
- ‚úÖ Good quality

**Cons:**
- ‚ùå More expensive than GPT-3.5
- ‚ùå Not as good as GPT-4/5

**Cost Estimate**: ~$1-2 for 100 events

**Deployment Name**: `gpt-4-turbo` or `gpt-4-turbo-preview`

---

### üí∞ GPT-3.5 Turbo (Budget Option)
**Status**: ‚úÖ Widely available

**Best For**:
- ‚úÖ Development/testing
- ‚úÖ Routine events
- ‚úÖ Cost-sensitive scenarios

**Pros:**
- ‚úÖ Very cheap
- ‚úÖ Fast
- ‚úÖ Good enough for simple cases

**Cons:**
- ‚ùå Less sophisticated reasoning
- ‚ùå May miss technical nuances

**Cost Estimate**: ~$0.20-0.50 for 100 events

**Deployment Name**: `gpt-35-turbo` or `gpt-3.5-turbo`

---

## Recommendation for Hackathon

### ü•á First Choice: GPT-5 Pro
**If available in your Azure region**, use GPT-5 Pro:
- Most impressive for judges
- Best technical analysis
- Shows you're using cutting-edge AI

**Setup**:
```bash
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-5-pro
```

### ü•à Second Choice: GPT-4
**If GPT-5 Pro not available**, use GPT-4:
- Excellent quality
- Widely available
- Reliable performance

**Setup**:
```bash
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
```

### ü•â Budget Choice: GPT-3.5 Turbo
**If cost is a major concern**:
- Still good quality
- Much cheaper
- Fast responses

**Setup**:
```bash
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-35-turbo
```

## How to Check Available Models

1. Go to Azure Portal ‚Üí Your OpenAI resource
2. Click "Model deployments"
3. Click "Create" to see available models
4. Look for:
   - `gpt-5-pro` (if available)
   - `gpt-4`
   - `gpt-4-turbo`
   - `gpt-35-turbo`

## Model Comparison Table

| Model | Quality | Speed | Cost (100 events) | Availability | Best For |
|-------|---------|-------|-------------------|--------------|----------|
| **GPT-5 Pro** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Slow | $5-10 | Limited | Impressive demos |
| **GPT-4** | ‚≠ê‚≠ê‚≠ê‚≠ê | Medium | $2-5 | ‚úÖ Wide | Hackathon (recommended) |
| **GPT-4 Turbo** | ‚≠ê‚≠ê‚≠ê‚≠ê | Fast | $1-2 | ‚úÖ Wide | Balanced |
| **GPT-3.5 Turbo** | ‚≠ê‚≠ê‚≠ê | Fast | $0.20-0.50 | ‚úÖ Wide | Budget |

## Quick Decision Guide

**Want to impress judges?** ‚Üí GPT-5 Pro (if available) or GPT-4
**Budget conscious?** ‚Üí GPT-3.5 Turbo
**Need speed?** ‚Üí GPT-4 Turbo or GPT-3.5 Turbo
**Best overall?** ‚Üí GPT-4 (reliable, available, good quality)

## Updating Your Configuration

Edit your `.env` file:
```bash
# For GPT-5 Pro (if available)
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-5-pro

# OR for GPT-4 (recommended)
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# OR for GPT-3.5 Turbo (budget)
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-35-turbo
```

Then restart your backend:
```bash
./start_backend.sh
```

